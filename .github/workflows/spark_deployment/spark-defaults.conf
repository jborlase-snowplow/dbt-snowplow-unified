# Spark Master Configuration
spark.master                                   local[3]

# Storage and Catalog Configuration
spark.sql.warehouse.dir                        s3a://dbt-spark-iceberg/github-integration-testing
spark.sql.catalog.glue                         org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.glue.catalog-impl            org.apache.iceberg.aws.glue.GlueCatalog
spark.sql.catalog.glue.warehouse               s3a://dbt-spark-iceberg/github-integration-testing
spark.sql.catalog.glue.io-impl                 org.apache.iceberg.aws.s3.S3FileIO
spark.sql.defaultCatalog                       glue
spark.sql.catalog.glue.database                dbt-spark-iceberg

# AWS S3 Configuration
spark.hadoop.fs.s3a.impl                       org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.aws.credentials.provider   org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider
spark.hadoop.fs.s3a.endpoint                   s3.eu-west-1.amazonaws.com
spark.hadoop.fs.s3a.region                     eu-west-1
spark.hadoop.fs.s3a.connection.maximum         200
spark.hadoop.fs.s3a.connection.timeout         1200000
spark.hadoop.fs.s3a.connection.establish.timeout 1200000
spark.hadoop.fs.s3a.attempts.maximum           20
spark.hadoop.fs.s3a.retry.limit               20
spark.hadoop.fs.s3a.retry.interval            1000
spark.hadoop.fs.s3a.fast.upload               true
spark.hadoop.fs.s3a.fast.upload.buffer        disk
spark.hadoop.fs.s3a.multipart.size            64M

# Memory and Resource Configuration - Aggressive for GitHub Runner
spark.driver.memory                            10g
spark.executor.memory                          3g
spark.memory.fraction                          0.85
spark.memory.storageFraction                   0.3
spark.driver.maxResultSize                     2g
spark.sql.shuffle.partitions                   6
spark.default.parallelism                      6

# Performance Optimization
spark.sql.adaptive.enabled                     true
spark.sql.adaptive.coalescePartitions.enabled  true
spark.sql.adaptive.skewJoin.enabled           true
spark.sql.adaptive.localShuffleReader.enabled  true
spark.sql.adaptive.fetchShuffleBlocksInBatch  true
spark.sql.files.maxPartitionBytes             134217728
spark.serializer                              org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max               256m
spark.sql.inMemoryColumnarStorage.compressed  true
spark.sql.inMemoryColumnarStorage.batchSize   10000
spark.sql.shuffle.file.buffer                 1m
spark.shuffle.file.buffer                     1m
spark.shuffle.compress                        true
spark.shuffle.spill.compress                  true

# I/O Optimization
spark.sql.files.openCostInBytes               134217728
spark.sql.broadcastTimeout                     600s
spark.sql.autoBroadcastJoinThreshold          10485760
spark.sql.files.maxRecordsPerFile             50000000

# Timeout and Network Configuration
spark.network.timeout                          600s
spark.executor.heartbeatInterval              60s
spark.storage.blockManagerSlaveTimeoutMs      180s

# Off-heap Memory Configuration
spark.memory.offHeap.enabled                  true
spark.memory.offHeap.size                     2g

# Debug Logging
spark.driver.extraJavaOptions                 -Dlog4j.rootCategory=INFO,console -Dlog4j.logger.org.apache.spark.network.netty=INFO -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions
spark.executor.extraJavaOptions               -XX:+UseG1GC -XX:+UnlockDiagnosticVMOptions