# Catalog and Core Configuration
spark.sql.warehouse.dir                        s3a://dbt-spark-iceberg/github-integration-testing
spark.sql.catalog.glue                         org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.glue.catalog-impl            org.apache.iceberg.aws.glue.GlueCatalog
spark.sql.catalog.glue.warehouse               s3a://dbt-spark-iceberg/github-integration-testing
spark.sql.catalog.glue.io-impl                 org.apache.iceberg.aws.s3.S3FileIO
spark.sql.defaultCatalog                       glue
spark.sql.catalog.glue.database                dbt-spark-iceberg

# Performance Tuning
spark.master                                   local[3]
spark.driver.memory                            10g
spark.executor.memory                          3g
spark.memory.fraction                          0.85
spark.memory.storageFraction                   0.3
spark.driver.maxResultSize                     2g
spark.sql.shuffle.partitions                   6
spark.default.parallelism                      6

# Network Resilience
spark.network.timeout                          800s
spark.executor.heartbeatInterval              100s
spark.storage.blockManagerSlaveTimeoutMs      300s
spark.rpc.io.maxRetries                       10
spark.rpc.askTimeout                          600s
spark.rpc.lookupTimeout                       600s
spark.network.maxRetries                      10
spark.network.retryWait                       5s

# S3/AWS Configuration
spark.hadoop.fs.s3a.connection.timeout         300000
spark.hadoop.fs.s3a.connection.maximum         200
spark.hadoop.fs.s3a.attempts.maximum           20
spark.hadoop.fs.s3a.retry.limit               20
spark.hadoop.fs.s3a.retry.interval            1000
spark.hadoop.fs.s3a.impl                      org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.fast.upload               true
spark.hadoop.fs.s3a.fast.upload.buffer        disk
spark.hadoop.fs.s3a.multipart.size            64M
spark.hadoop.fs.s3a.connection.establish.timeout 300000
spark.hadoop.fs.s3a.socket.recv.buffer        65536
spark.hadoop.fs.s3a.socket.send.buffer        65536
spark.hadoop.fs.s3a.readahead.range           64M
spark.hadoop.fs.s3a.aws.credentials.provider  org.apache.hadoop.fs.s3a.TemporaryAWSCredentialsProvider

# Iceberg Configuration
spark.sql.iceberg.handle-timestamp-without-timezone true
spark.sql.extensions                           org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
spark.wds.iceberg.format-version              2
spark.sql.parquet.compression.codec           zstd
spark.sql.parquet.mergeSchema                true
spark.sql.parquet.filterPushdown             true

# Adaptive Query Execution
spark.sql.adaptive.enabled                     true
spark.sql.adaptive.coalescePartitions.enabled  true
spark.sql.adaptive.skewJoin.enabled           true
spark.sql.adaptive.localShuffleReader.enabled  true
spark.sql.adaptive.fetchShuffleBlocksInBatch  true

# Memory Management
spark.memory.offHeap.enabled                  true
spark.memory.offHeap.size                     2g

# Error Recovery and Resilience
spark.task.maxFailures                        8
spark.speculation                             true
spark.speculation.multiplier                  3
spark.speculation.quantile                    0.75
spark.executor.extraJavaOptions              -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError
spark.driver.extraJavaOptions               -XX:+UseG1GC -XX:+ExitOnOutOfMemoryError

# Thrift Server Configuration
spark.sql.hive.thriftServer.async             true
spark.sql.hive.thriftServer.maxWorkerThreads  6
spark.sql.hive.thriftServer.minWorkerThreads  4