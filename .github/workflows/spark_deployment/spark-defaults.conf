# Spark Master Configuration
spark.master                                   local[*]  # Run in local mode using all available cores

# Storage and Catalog Configuration
spark.sql.warehouse.dir                        s3a://dbt-spark-iceberg/github-integration-testing
spark.sql.catalog.glue                         org.apache.iceberg.spark.SparkCatalog
spark.sql.catalog.glue.catalog-impl            org.apache.iceberg.aws.glue.GlueCatalog
spark.sql.catalog.glue.warehouse               s3a://dbt-spark-iceberg/github-integration-testing
spark.sql.catalog.glue.io-impl                 org.apache.iceberg.aws.s3.S3FileIO
spark.sql.defaultCatalog                       glue
spark.sql.catalog.glue.database                dbt-spark-iceberg

# AWS S3 Configuration
spark.hadoop.fs.s3a.impl                       org.apache.hadoop.fs.s3a.S3AFileSystem
spark.hadoop.fs.s3a.access.key                 ${AWS_ACCESS_KEY_ID}
spark.hadoop.fs.s3a.secret.key                 ${AWS_SECRET_ACCESS_KEY}
spark.hadoop.fs.s3a.endpoint                   s3.eu-west-1.amazonaws.com
spark.hadoop.fs.s3a.path.style.access          true
spark.hadoop.fs.s3a.region                     eu-west-1
spark.hadoop.fs.s3a.aws.region                 eu-west-1
spark.hadoop.com.amazonaws.services.s3.enableV4 true
spark.hadoop.fs.s3a.aws.credentials.provider   org.apache.hadoop.fs.s3a.SimpleAWSCredentialsProvider

# Glue Configuration
spark.hadoop.hive.metastore.client.factory.class com.amazonaws.glue.catalog.metastore.AWSGlueDataCatalogHiveClientFactory

# Memory and Resource Configuration
spark.driver.memory                           8g    # Half of available RAM
spark.executor.memory                         4g    # Quarter of available RAM
spark.memory.fraction                         0.7   # Fraction of heap space used for execution and storage
spark.memory.storageFraction                  0.3   # Fraction of spark.memory.fraction used for storage
spark.driver.maxResultSize                    2g    # Limit result collection size
spark.sql.shuffle.partitions                  8     # 2x number of cores
spark.default.parallelism                     8     # 2x number of cores

# Performance Optimization
spark.sql.adaptive.enabled                    true
spark.sql.adaptive.coalescePartitions.enabled true
spark.sql.adaptive.skewJoin.enabled          true
spark.sql.files.maxPartitionBytes            134217728  # 128MB
spark.serializer                             org.apache.spark.serializer.KryoSerializer
spark.kryoserializer.buffer.max              256m
spark.sql.inMemoryColumnarStorage.compressed true
spark.sql.inMemoryColumnarStorage.batchSize  10000

# Timeout and Network Configuration
spark.network.timeout                         300s   # Reduced from 600s
spark.sql.broadcastTimeout                    300s   # Reduced from 600s

# Event Logging - Limited for GitHub Actions environment
spark.eventLog.enabled                        true
spark.eventLog.dir                           /tmp/spark-events
spark.eventLog.rolling.enabled               true
spark.eventLog.rolling.maxFileSize           128m   # Limit event log file size

# Memory Management
spark.memory.offHeap.enabled                 true
spark.memory.offHeap.size                    2g    # Off-heap memory allocation

# Garbage Collection
spark.executor.extraJavaOptions              -XX:+UseG1GC -XX:G1HeapRegionSize=16M -XX:+UseCompressedOops