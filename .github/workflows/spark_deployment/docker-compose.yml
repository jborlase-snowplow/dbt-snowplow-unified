version: '3'

networks:
  spark-network:
    driver: bridge

services:
  thrift-server:
    image: snowplow/spark-s3-iceberg:latest
    ports:
      - '10000:10000'
      - '4040:4040'
    environment:
      - SPARK_LOCAL_IP=thrift-server
      # AWS credentials
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_SESSION_TOKEN=${AWS_SESSION_TOKEN}
      - AWS_REGION=eu-west-1
      - AWS_DEFAULT_REGION=eu-west-1
    deploy:
      resources:
        limits:
          cpus: '3.5'
          memory: 14GB
        reservations:
          cpus: '2'
          memory: 10GB
    volumes:
      - ./spark-defaults.conf:/spark/conf/spark-defaults.conf
      - ./setup.sh:/setup.sh
    entrypoint: ["/bin/bash", "/setup.sh"]
    command: ["/bin/bash", "-c", "/spark/sbin/start-thriftserver.sh \
              --master local[3] \
              --driver-memory 10g \
              --executor-memory 3g \
              --conf spark.sql.hive.thriftServer.async=true \
              --conf spark.sql.hive.thriftServer.maxWorkerThreads=6 \
              --conf spark.sql.catalog.spark_catalog=org.apache.iceberg.spark.SparkCatalog \
              --conf spark.sql.catalog.spark_catalog.catalog-impl=org.apache.iceberg.aws.glue.GlueCatalog \
              --conf spark.sql.catalog.spark_catalog.warehouse=s3a://dbt-spark-iceberg/github-integration-testing \
              --conf spark.sql.catalog.spark_catalog.io-impl=org.apache.iceberg.aws.s3.S3FileIO \
              --conf spark.sql.defaultCatalog=spark_catalog \
              --conf spark.sql.catalog.spark_catalog.default-namespace=default_snowplow_manifest \
              --conf spark.sql.catalog.spark_catalog.table-default.write.object-storage.enabled=true \
              --conf spark.sql.catalog.spark_catalog.table-default.write.wap.enabled=true \
              --conf spark.sql.catalog.spark_catalog.table-default.merge.cardinality.check.enabled=false \
              --conf spark.sql.catalog.spark_catalog.table-default.write.distribution-mode=none \
              --conf spark.sql.catalog.spark_catalog.table-default.write.update.mode=merge-on-read \
              --conf spark.sql.catalog.spark_catalog.table-default.write.delete.mode=merge-on-read \
              --conf spark.sql.catalog.spark_catalog.table-default.format-version=2 \
              --conf spark.sql.catalog.spark_catalog.table-default.write.format.default=parquet \
              --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
              && tail -f /spark/logs/spark--org.apache.spark.sql.hive.thriftserver.HiveThriftServer2-*.out"]
    networks:
      - spark-network